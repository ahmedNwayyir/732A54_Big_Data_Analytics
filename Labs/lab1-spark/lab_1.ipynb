{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[['102170', '2013-11-01', '06:00:00', '6.8', 'G'], ['102170', '2013-11-01', '18:00:00', '3.8', 'G'], ['102170', '2013-11-02', '06:00:00', '5.8', 'G'], ['102170', '2013-11-02', '18:00:00', '-1.1', 'G'], ['102170', '2013-11-03', '06:00:00', '-0.2', 'G'], ['102170', '2013-11-03', '18:00:00', '5.6', 'G'], ['102170', '2013-11-04', '06:00:00', '6.5', 'G'], ['102170', '2013-11-04', '18:00:00', '5.1', 'G'], ['102170', '2013-11-05', '06:00:00', '4.2', 'G'], ['102170', '2013-11-05', '18:00:00', '3.2', 'G']]\n"
     ]
    }
   ],
   "source": [
    "from pyspark import SparkContext, SparkConf\n",
    "\n",
    "conf = SparkConf().setAppName(\"Lab_1\").setMaster(\"local[*]\")\n",
    "sc = SparkContext.getOrCreate()\n",
    "# sc.setLogLevel(\"Error\")\n",
    "\n",
    "# This path is to the file on hdfs\n",
    "temperature_file = sc.textFile(\"Data/temperature-readings-small.csv\")\n",
    "# (station, year-month-day, time, temperature, quality)\n",
    "lines = temperature_file.map(lambda line: line.split(\";\"))\n",
    "\n",
    "print(lines.take(10))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[('2014', (-24.3, 29.1)), ('2013', (-13.3, 10.2))]\n"
     ]
    }
   ],
   "source": [
    "## Q1\n",
    "# lowest and highest temperatures measured each year for the period 1950-2014, descending.\n",
    "\n",
    "# (key, value) = (year,temperature)\n",
    "year_temp = lines.map(lambda x: (x[1][0:4], float(x[3])))\n",
    "# Readings during 1950-2014\n",
    "filtered_temp = year_temp.filter(lambda x: int(x[0])>=1950 and int(x[0])<=2014)\n",
    "\n",
    "# take min => take max => join\n",
    "min_temp = filtered_temp.reduceByKey(min)\n",
    "max_temp = filtered_temp.reduceByKey(max)\n",
    "min_max  = min_temp.join(max_temp)\n",
    "\n",
    "# sort => combine in 1 file\n",
    "min_max = min_max.sortBy(ascending = False, keyfunc=lambda k: k[1][1])\n",
    "min_max = min_max.repartition(1)\n",
    "\n",
    "# (year, (min, max)) \n",
    "print(min_max.take(10))\n",
    "# min_max.saveAsTextFile(\"A1\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[('2014-07', 62), ('2014-08', 56), ('2014-06', 54), ('2014-05', 31), ('2014-09', 25), ('2014-10', 17), ('2014-04', 9), ('2013-11', 1), ('2014-11', 1)]\n"
     ]
    }
   ],
   "source": [
    "## Q2_1\n",
    "# Monthly readings higher than 10 degrees\n",
    "\n",
    "# (year-month, (station, temperature))\n",
    "monthly_temp = lines.map(lambda x: (x[1][0:7], (x[0], float(x[3]))))\n",
    "# Readings during 1950-2014 & > 10\n",
    "filtered_temp = monthly_temp.filter(lambda x: int(x[0][0:4]) >= 1950 and int(x[0][0:4]) <=2014 and float(x[1][1]) > 10)\n",
    "\n",
    "# ((year-month), 1) => ((year-month), count) => combine => sort\n",
    "counter = filtered_temp.map(lambda x: (x[0], 1))\n",
    "monthly_count = counter.reduceByKey(lambda a,b: a+b)\n",
    "RDD_combined  = monthly_count.repartition(1) \n",
    "sorted_count  = RDD_combined.sortBy(ascending = False, keyfunc=lambda k: k[1])\n",
    "\n",
    "print(sorted_count.take(10))\n",
    "# sorted_count.saveAsTextFile(\"A2_1\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[('2014-01', 1), ('2014-02', 1), ('2014-03', 1), ('2014-05', 1), ('2014-06', 1), ('2014-08', 1), ('2014-09', 1), ('2014-12', 1), ('2013-11', 1), ('2013-12', 1)]\n"
     ]
    }
   ],
   "source": [
    "## Q2_2\n",
    "# Distinct readings by station per month higher than 10 degrees\n",
    "\n",
    "# ((year-month),(station,1)) and only taking one reading per month per station\n",
    "filtered_temp = monthly_temp.map(lambda x: (x[0], (x[1][0],1))).distinct() \n",
    "\n",
    "# ((year-month), (station, count))\n",
    "dist_count = filtered_temp.reduceByKey(lambda a,b: (a[0], (a[1]+b[1])))\n",
    "\n",
    "# map to ((year-month), (count)) => combine => sort\n",
    "arranged_count = dist_count.map(lambda x: (x[0], x[1][1]))\n",
    "RDD_combined = arranged_count.repartition(1) \n",
    "sorted_count = RDD_combined.sortBy(ascending = False, keyfunc=lambda k: k[1])\n",
    "\n",
    "print(sorted_count.take(10))\n",
    "# sorted_count.saveAsTextFile(\"A2_2\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[(('2014-07', '102170'), 19.65967741935484), (('2014-06', '102170'), 14.443333333333332), (('2014-08', '102170'), 13.869354838709679), (('2014-05', '102170'), 10.756451612903227), (('2014-09', '102170'), 8.584999999999999), (('2014-10', '102170'), 7.106451612903226), (('2014-04', '102170'), 4.776666666666667), (('2014-11', '102170'), 2.525), (('2014-03', '102170'), 1.8967741935483873), (('2013-12', '102170'), 0.7096774193548387)]\n"
     ]
    }
   ],
   "source": [
    "## Q3\n",
    "# Average monthly temperature\n",
    "\n",
    "# ((year-month-day, station), (temperature))\n",
    "station_temp = lines.map(lambda x: ((x[1][0:10], x[0]), (float(x[3]))))\n",
    "# Readings during 1960-2014\n",
    "filtered_temp = station_temp.filter(lambda x: int(x[0][0][0:4]) >= 1960 and int(x[0][0][0:4]) <=2014)\n",
    "\n",
    "min_temp = filtered_temp.reduceByKey(min)\n",
    "max_temp = filtered_temp.reduceByKey(max)\n",
    "# ((year-month-day, station), (min, max))\n",
    "min_max  = min_temp.join(max_temp)\n",
    "\n",
    "# ((year-month, station), 1)\n",
    "counter = min_max.map(lambda x: ((x[0][0][0:7], x[0][1]), 1))\n",
    "# ((year-month, station), count)\n",
    "count   = counter.reduceByKey(lambda a,b: (a+b))\n",
    "\n",
    "# ((year-month, station), (min, max))\n",
    "daily_min_max = min_max.map(lambda x: ((x[0][0][0:7], x[0][1]), (x[1])))\n",
    "# ((year-month, station), (min_sum, max_sum))\n",
    "min_max_sum   = daily_min_max.reduceByKey(lambda a,b: ((a[0]+b[0]), (a[1]+b[1])))\n",
    "\n",
    "# ((year-month, station), ((min_sum, max_sum), count))\n",
    "joint_RDD = min_max_sum.join(count)\n",
    "\n",
    "# ((year-month, station), average) where average taken as (min_sum + max_sum / count * 2)\n",
    "avg_temp = joint_RDD.map(lambda x: (x[0], ((x[1][0][0]+x[1][0][1])/(x[1][1]*2))))\n",
    "avg_temp = avg_temp.sortBy(ascending = False, keyfunc=lambda k: k[1])\n",
    "\n",
    "print(avg_temp.take(10))\n",
    "# avg_temp.saveAsTextFile(\"A3\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[(('103100', '1995-08-30'), 0.0), (('103100', '1995-08-31'), 0.0), (('103100', '1995-09-03'), 3.2), (('103100', '1995-09-04'), 12.3), (('103100', '1995-09-11'), 3.0000000000000004), (('103100', '1995-09-12'), 0.4), (('103100', '1995-09-14'), 0.0), (('103100', '1995-09-19'), 0.0), (('103100', '1995-09-20'), 0.3), (('103100', '1995-09-22'), 0.0)]\n"
     ]
    }
   ],
   "source": [
    "## Q4\n",
    "# Stations with 25-30 degrees maximum temperature and 100-200mm maximum percipitation\n",
    "\n",
    "# This path is to the file on hdfs\n",
    "temperature_file = sc.textFile(\"Data/temperature-readings-small.csv\")\n",
    "# (station, year-month-day, time, temperature, quality)\n",
    "lines = temperature_file.map(lambda line: line.split(\";\"))\n",
    "\n",
    "# (station, temperature)\n",
    "station_temp = lines.map(lambda x: (x[0], float(x[3])))\n",
    "max_temp = station_temp.reduceByKey(max)\n",
    "# Maximum temperature between 25 and 30 degrees\n",
    "filtered_max_temp = max_temp.filter(lambda x: float(x[1])>=25 and float(x[1])<=30)\n",
    "\n",
    "percipitation_file = sc.textFile(\"Data/precipitation-readings.csv\")\n",
    "# (station, year-month-day, time, percipitation, quality)\n",
    "perc_lines = percipitation_file.map(lambda line: line.split(\";\"))\n",
    "\n",
    "# (station, percipitation)\n",
    "station_perc = perc_lines.map(lambda x: ((x[0], x[1]), (float(x[3]))))\n",
    "perc_sum = station_perc.reduceByKey(lambda a,b: (a+b))\n",
    "# Maximum percipitation between 100 and 200mm\n",
    "filtered_max_perc = perc_sum.filter(lambda x: x[1]>=100 and x[1]<=200).map(lambda x: (x[0][0], x[1]))\n",
    "\n",
    "result = filtered_max_temp.join(filtered_max_perc)\n",
    "result = result.repartition(1)\n",
    "\n",
    "print(perc_sum.take(10))\n",
    "# max_temp.saveAsTextFile(\"A3\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[]\n"
     ]
    }
   ],
   "source": [
    "\n",
    "\n",
    "# This path is to the file on hdfs\n",
    "stations_file = sc.textFile(\"Data/stations-Ostergotland.csv\")\n",
    "station_lines = stations_file.map(lambda line: line.split(\";\"))\n",
    "# (stations)\n",
    "stations = station_lines.map(lambda x: x[0]).collect()\n",
    "\n",
    "percipitation_file = sc.textFile(\"Data/precipitation-readings.csv\")\n",
    "# (station, year-month-day, time, percipitation, quality)\n",
    "perc_lines = percipitation_file.map(lambda line: line.split(\";\"))\n",
    "\n",
    "# ((station, year, month), (percipitation, 1))\n",
    "prec_rdd = perc_lines.map(lambda x: ((x[0], x[1][0:4], x[1][5:7]), (float(x[3]), 1)))\n",
    "precByStation = prec_rdd.filter(lambda x: x[0][0] in stations and int(x[0][1])>=1993 and int(x[0][1])<=2016)\n",
    "#precByStation = precByStation.map(lambda x: ((x[0][1], x[0][2]), x[1]))\n",
    "#precByStation = precByStation.reduceByKey(lambda x,y: (x[0]+y[0], x[1]+y[1])).map(lambda x: (x[0], x[1][0]/x[1][1])).sortByKey(False)\n",
    "#sortByKey(False)\n",
    "\n",
    "print(precByStation.take(10))\n",
    "#stations.saveAsTextFile(\"BDA/output/Lab_1/A5\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
